{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWtmuTmn4e5o"
      },
      "outputs": [],
      "source": [
        "from keras.datasets.cifar10 import load_data\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test) = load_data()\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "mlrG-ioJ5CBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Conv2D,Flatten,LeakyReLU,Dropout,Reshape,Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "CGD43XmE5Ec4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discriminator model:**"
      ],
      "metadata": {
        "id": "SbXJZiijaVrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator(in_shape = (32,32,3)):\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(64,(3,3),padding= \"same\" , input_shape = in_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128,(3,3),padding= \"same\" , strides=(2,2)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(128,(3,3),padding= \"same\" , strides=(2,2)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(256,(3,3),padding= \"same\" , strides=(2,2)))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "  opt = Adam(learning_rate=0.0002,beta_1=0.5)\n",
        "\n",
        "  model.compile(optimizer = opt, loss = 'binary_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "VY3Kj8hY5JA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = discriminator()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4w1-2fM5LRm",
        "outputId": "07e610e9-59b6-451c-ffab-cd39748c4859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 521345 (1.99 MB)\n",
            "Trainable params: 521345 (1.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_real_sample():\n",
        "  (x_train,_),(_,_) = load_data()\n",
        "  x = x_train.astype('float32')\n",
        "  x = (x-127.5)/127.5\n",
        "  return x\n",
        "\n",
        "x = load_real_sample()\n",
        "# x.shape"
      ],
      "metadata": {
        "id": "p1gfEA6P5NNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_real_sample(dataset,n_sample):\n",
        "  ix = np.random.randint(0,dataset.shape[0],n_sample)\n",
        "  x = dataset[ix]\n",
        "  y = np.ones((n_sample,1))\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "Nzgtgwzu5Sjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_sample(n_sample):\n",
        "  x = np.random.rand(32 * 32 * 3 * n_sample)\n",
        "  x = -1 + x * 2\n",
        "  x = x.reshape((n_sample,32,32,3))\n",
        "  y = np.zeros((n_sample,1))\n",
        "  return x,y\n",
        "\n",
        "x,y = generate_fake_sample(64)"
      ],
      "metadata": {
        "id": "-czBLmFA5bAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator(model,dataset,n_iter=20,n_batch=128):\n",
        "  half_batch = n_batch//2\n",
        "\n",
        "  for i in range(n_iter):\n",
        "    x_real,y_real = generate_real_sample(dataset,half_batch)\n",
        "    _,real_acc = model.train_on_batch(x_real,y_real)\n",
        "    x_fake,y_fake = generate_fake_sample(half_batch)\n",
        "    _,fake_acc = model.train_on_batch(x_fake,y_fake)\n",
        "    print(f'{i+1} . real = {real_acc * 100}% , fake = {fake_acc * 100}% ')"
      ],
      "metadata": {
        "id": "JePA-8z15hoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = discriminator()\n",
        "dataset = load_real_sample()\n",
        "\n",
        "train_discriminator(model,dataset)"
      ],
      "metadata": {
        "id": "_YAeatm37TYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJkwjzptZ-2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generator Model:**"
      ],
      "metadata": {
        "id": "WUNbxmFQaFZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator(latent_dim):\n",
        "\n",
        "  model = Sequential()\n",
        "  n_nodes = 256*4*4\n",
        "\n",
        "  model.add(Dense(n_nodes,input_dim = latent_dim))\n",
        "  model.add(LeakyReLU(alpha = 0.2))\n",
        "  model.add(Reshape((4,4,256)))\n",
        "\n",
        "  model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding = 'same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding = 'same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2DTranspose(128,(4,4),strides=(2,2),padding = 'same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Conv2D(3,(3,3),activation='tanh',padding='same'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "59K3ls2M7XTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = generator(100)\n",
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4HdV01Y7-EE",
        "outputId": "0d542b04-1274-46ac-ee55-f65ce6d23cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 4096)              413696    \n",
            "                                                                 \n",
            " leaky_re_lu_16 (LeakyReLU)  (None, 4096)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 128)         524416    \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " leaky_re_lu_17 (LeakyReLU)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 128)       262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_18 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 128)       262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_19 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 32, 32, 3)         3459      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1466115 (5.59 MB)\n",
            "Trainable params: 1466115 (5.59 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_latent_points(latent_dim,n_sample):\n",
        "\n",
        "  x_input = np.random.randn(latent_dim * n_sample)\n",
        "  x_input = x_input.reshape(n_sample,latent_dim)\n",
        "  return x_input"
      ],
      "metadata": {
        "id": "om-0s9uq8BV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_sample_gen(g_model,latent_dim,n_sample):\n",
        "  x_input = generate_latent_points(latent_dim,n_sample)\n",
        "  x = g_model.predict(x_input)\n",
        "  y = np.zeros((n_sample,1))\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "QG-S4Lr68Fx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = generator(100)\n",
        "x,y = generate_fake_sample_gen(model,100,49)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-fur2-zy8JQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAN:**"
      ],
      "metadata": {
        "id": "AxhTjmUKcEeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gan(g_model,d_model):\n",
        "  d_model.trainable = False\n",
        "  model = Sequential()\n",
        "  model.add(g_model)\n",
        "  model.add(d_model)\n",
        "  opt = Adam(learning_rate = 0.0002,beta_1 = 0.5)\n",
        "  model.compile(optimizer = opt,loss = 'binary_crossentropy')\n",
        "  return model"
      ],
      "metadata": {
        "id": "SFP9u3kL8P-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = discriminator()\n",
        "g_model = generator(100)\n",
        "model = gan(g_model,d_model)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj8Y8ANc8X8V",
        "outputId": "de784221-486e-4413-fd6f-1518c62c8dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_10 (Sequential)  (None, 32, 32, 3)         1466115   \n",
            "                                                                 \n",
            " sequential_9 (Sequential)   (None, 1)                 522497    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1988612 (7.59 MB)\n",
            "Trainable params: 1466115 (5.59 MB)\n",
            "Non-trainable params: 522497 (1.99 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summerize_function(i,g_model,d_model,dataset,latent_dim,n_samples = 150):\n",
        "\n",
        "  x_real,y_real = generate_real_sample(dataset,n_samples)\n",
        "  _,acc_real = d_model.evaluate(x_real,y_real)\n",
        "\n",
        "  x_fake,y_fake = generate_fake_sample_gen(g_model,latent_dim,n_samples)\n",
        "  _,acc_fake = d_model.evaluate(x_fake,y_fake)\n",
        "\n",
        "  print(f'Discriminator Accuracy: Real = {acc_real} , Fake = {acc_fake}')\n",
        "  save_plot(x_fake,i)\n",
        "  filename = 'model_%03d.h5' % (i+1)\n",
        "  g_model.save(filename)"
      ],
      "metadata": {
        "id": "R4J129hJ8qIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(g_model,d_model,gan_model,dataset,latent_dim,n_epochs=20,n_batch=128):\n",
        "\n",
        "  batch_per_epoch = dataset.shape[0]//n_batch\n",
        "  half_batch = n_batch//2\n",
        "\n",
        "  for i in range(n_epochs):\n",
        "    for j in range(batch_per_epoch):\n",
        "\n",
        "      x_real,y_real = generate_real_sample(dataset,half_batch)\n",
        "      d_loss1,_ = d_model.train_on_batch(x_real,y_real)\n",
        "\n",
        "      x_fake,y_fake = generate_fake_sample_gen(g_model,latent_dim,half_batch)\n",
        "      d_loss2,_ = d_model.train_on_batch(x_fake,y_fake)\n",
        "\n",
        "      x_gan = generate_latent_points(latent_dim,n_batch)\n",
        "      y_gan = np.ones((n_batch,1))\n",
        "      g_loss = gan_model.train_on_batch(x_gan,y_gan)\n",
        "\n",
        "      print(f'{i+1}. {j+1}/{batch_per_epoch} : d1 = {d_loss1} , d2 = {d_loss2} , g = {g_loss}')\n",
        "\n",
        "    if (i+1)%10 == 0:\n",
        "      summerize_function(i,g_model,d_model,dataset,latent_dim)\n"
      ],
      "metadata": {
        "id": "iduk9jxi8dBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_model = discriminator()\n",
        "g_model = generator(100)\n",
        "\n",
        "gan_model = gan(g_model,d_model)\n",
        "train(g_model,d_model,gan_model,dataset,latent_dim=100,n_epochs=200,n_batch=128)"
      ],
      "metadata": {
        "id": "uqYV-07N8wma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plot(example,epoch,n=7):\n",
        "\n",
        "  example = (example + 1)/2.0\n",
        "\n",
        "  for i in range(n * n):\n",
        "    plt.subplot(n,n,i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(example[i])\n",
        "  filename = 'plot_e%03d.png' % (epoch+1)\n",
        "\n",
        "  plt.savefig(filename)\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "smmZi0PT8uAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FqA1fghG8yhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGXDWp2i8282"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}